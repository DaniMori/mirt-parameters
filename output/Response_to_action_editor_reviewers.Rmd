---
output:
  officedown::rdocx_document:
    mapstyles:
      First Paragraph: Body Text
    base_format: bookdown::word_document2
    reference_docx: ../www/Template.docx
    number_sections: no
    keep_md:         no
bibliography: ../www/Multidimensional-parameters-MCLM.bib
csl:          ../www/apa-old-doi-prefix.csl
editor_options: 
  chunk_output_type: console
---

```{r setup}
#| include: false

# Includes:

library(here)
library(knitr)
library(patchwork)
library(ggplot2)
library(rstudioapi)
library(svglite) # Used by {knitr} and {ggplot2} to render the figure to SVG;
                 #   added to prevent {renv} from reporting inconsistent state.
library(officer)

ROOT_DIR <- here()
DOC_DIR  <- file.path(ROOT_DIR, "output")

opts_knit$set(root.dir = ROOT_DIR)
opts_chunk$set(
  echo     = FALSE,
  message  = FALSE,
  cache    = FALSE,
  dev      = "png",
  dpi      = 1200L,
  dev.args = list(type = "cairo-png"),
  tab.cap.fp_text = fp_text_lite(italic = FALSE, bold = TRUE),
  fig.cap.fp_text = fp_text_lite(italic = FALSE, bold = TRUE)
)

# Output configuration options:
options(digits = 3)
```

```{r sources}
#| cache:   false
#| include: false
source("R/Formulae.R",  encoding = 'UTF-8')
source("R/Constants.R", encoding = 'UTF-8')
```

# Responses to the action editor:

###### I have a concern with making the latent ability axes nonorthogonal to represent the covariance structure between the latent abilities. Recognizing that the data used to estimate MIRT parameters represents an interaction between the examinees and the items and that different groups of examinees can result in different covariance structures and thus quite different item parameter estimates.

Indeed, different groups of examinees can result in different covariance structures.
However, in our understanding, the same fact can be predicated about the item parameters themselves, even without considering the covariance structure at all.
For example, in unidimensional IRT, the item parameters may be different for different groups of examinees, even if the variance is constrained to be equal across groups; this is indeed the basis of methods such as multigroup IRT.

It is our stance that the covariance structure, understood as a property of the data, of course, should be taken into account when determining the multidimensional properties of the items.
That is what we propose with the covariance-based (and correlation-based) versions of the multidimensional parameters.

###### The statement (p.13, line 8) about “the test space where item parameters naturally lie” needs greater explanation with examples.

We acknowledge and apologize for the lack of clarity in this sentence.
Please refer to our response to Reviewer 3 on p. <!-- TODO: Complete --> of this letter.

###### Like Reviewer 3, I do not understand how the magnitude of discrimination values (p 29 , 7) can be compared/interpreted values of discrimination are comparable from the two representations. It seems that the metric of the represented space has changed, and equivalent numbers will not have equivalent interpretations.

As the editor says, the basis used to represent the test space changes its metric.
We also understand that the metrics of the two representations are not comparable, and thus one should not compare items represented with the agnostic and the covariance-based version of the multidimensional parameters.
However, when making multi-group comparisons, we think that taking into account the covariance-based structure of the latent space will provide more realistic information, and thus one should use the covariance-based version.

In addition to other (minor) changes, we have added the following paragraph to our introduction to give an intuitive explanation of this fact:

> Take the following as an example:
A hypothetical complex item measures two latent traits with equal validity
---i.e., its discrimination parameters are equal with value $a$.
Applying Reckase & McKinley's [-@reckase_discriminating_1991] formula,
we would find that $`r MDISC_SYM` = \sqrt{2} a_i$.
Assume we apply this item in two groups where, taken to the extreme,
the two measured dimensions are orthogonal in the first group
and perfectly correlated in the second one.
While the previous formula seems correct in the first group,
one can intuitively say that,
because the two dimensions are *perfectly aligned* and thus
compound up in the second group,
the item `r MDISC_SYM` should be the algebraic sum of both components,
that is, $2 a_i$.
Similarly, the correlation between two simple items,
each one measuring a distinct dimension,
should be uncorrelated in the first group,
but perfectly correlated in the second one.
As the cosine between variables is usually understood as
the geometrical representation of their correlation,
the cosine between the two items should be 1 in the second group.
However, using an orthogonal representation
would yield null cosines in both cases.

There are several references in the literature that have found contradictory results which, we believe, are due to disregarding the latent covariance structure (i.e., using Reckase & McKinley's formulae in a non-orthonormal space).
For example, @min_evaluation_2007 [p. 49] computes the item parameters in the M2PL from a priori fixed values of $MDISC_i$ and $MDIFF_i$ (the name they use for $MID_i$), using @reckase_difficulty_1985 and @reckase_discriminating_1991's formulae.
They find that "[...] bias [...] was more apparent when ability distribution was separated from the
default distribution, such as was the case in groups 2 to 5".
They attribute this to a possible "degree of confounding among errors of parameter estimation and scale transformation", but their groups 2 to 5 happen to all have correlations equal (or almost equal) to .5.
(We consider that discussing these examples is out of the scope of this manuscript, but we will be glad to consider some of them if this editor deems it necessary.)

Also, we believe this is what happens when MIRT software such as NOHARM tries to force a correlated latent trait structure into its default orthogonal solution, as this editor himself has noted elsewhere [@ackerman_multidimensional_2005-1, p. 11].
While we consider this to be also out of the scope of the current paper, we will gladly add further details to explain why these results are contradictory and how our proposal may solve the problem.

###### I also wonder about how one compares the standard errors of the item parameters when the covariance covariance structures are different.  Are they directly comparable?

The standard errors of the multidimensional parameters are, without a doubt, more difficult to compute for the covariance-based case than for the agnostic one.
Computing the covariance errors in the former would require taking into account the standard errors of the item parameters themselves and at least the standard errors of the correlations (in the best-case scenario, assuming standard latent dimensions; otherwise, those of the variances and covariances).
However, to our knowledge, multidimensional item parameters, as defined by @reckase_difficulty_1985 and @reckase_discriminating_1991, have been previously defined and used only from a theoretical perspective, without ever taking into account the uncertainty resulting from the model estimation.

Regarding the "original" item parameters in the classical M2PL metric, we understand that the standard errors of the item parameters are independent of the definition of the multidimensional parameters used.
Software such as the R package {mirt} [@chalmers_mirt_2012] uses a method similar to exploratory factor analysis to compute the item parameter estimates and the standard errors, based on an oblique rotation to approximate simple structure.
One can see the help of the [`mirt()` function](https://www.rdocumentation.org/packages/mirt/versions/1.43/topics/mirt) therein (please see description of argument `SE.type`) for a detailed description of how this package computes the standard errors.

###### I would like to see the motivation and psychometric utility of this approach. Does it improve the interpretation of the latent abilities and thus result in more insight into how the results are used? The author needs to address this with legitimate examples for testing practitioners.

We think the motivation and psychometric utility of our approach are more related to the interpretation of the item parameters than with the latent abilities, which we believe exceeds the scope of this manuscript and could be the focus of another paper.
Please note that we only use the transformation in the latent space to an orthonormal basis as a reasoning artifact to obtain the proper expression of the item parameters in the general case, and that we do it in an abstract sense, before even considering whether the original basis is a representation of the covariance matrix.

However, to our understanding, the more precise interpretation of the item parameters that results from our approach indeed provides a better insight into how the results are used.
A multidimensional representation of the items provides benchmarks for comparing different latent trait levels, as discussed by @reckase_difficulty_1985.
Therefore, the more accurate such a representation is, the better the latent trait interpretation will be.

Please see our answer on p. <!-- TODO: Complete (3?) --> of this letter for an example of how the interpretation of the item parameters may change when considering the covariance structure.
<!-- TODO: Complete -->

###### What implications does your approach have for standard psychometric procedures like equating.

Fitting a single-group model where the latent dimensions are correlated affects the computation of the multidimensional parameters we propose here.
Given the scale underidentification in IRT, it is relatively common to fix the latent variances to 1, so it is unlikely that non-standard covariances affect these applications.
In this sense, we have mentioned in our discussion that "in many applications both [the covariance- and correlation-based] versions will be coincident, fortunately" (p. 31, lines 2-3, or p. <!-- TODO: Complete -->, lines <!-- TODO: Complete --> in the new version).
However, in multigroup procedures, such as equating and linking, non-standard (in some of the groups at least) may indeed affect the resulting multidimensional parameters.
Additionally, it is worth noting that the correlation matrix may differ among groups, which can also have a substantial effect on the multidimensional parameter values.
This is relevant because, even if the item parameters are equal across groups, the covariance structure may differ; thus, the multidimensional parameters will not be the same.
Conversely, the same multidimensional parameters may correspond to different parameter models if the latent covariance structure is different across groups.
Although it would be interesting to explore whether it is more realistic to assume equal M2PL parameters across groups (and thus possibly different multidimensional parameters) or vice-versa, we believe that this is an empirical question that lies outside the scope of our current manuscript.

We have probably made the mistake of assuming that this was implicitly understood, for which we apologize to the editor.
To improve and address this point better, we have made some additions to the second paragraph <!-- TODO: Third now? --> of our "Discussion" section (p. 30, lines 5-9 in the original submission, or p. <!-- TODO: Complete -->, lines <!-- TODO: Complete --> in the new one), which now reads:

> [...] Moreover, in applications where the latent space structure is critical
(e.g., multi-group IRT, equating, and linking),
the agnostic version may overlook relevant differences in
the values of the multidimensional parameters.
Different covariance structures across groups may significantly affect
the value of these parameters,
due to differences in either the variances or the correlation structure.
Therefore, even when the model parameters are equal across groups,
the multidimensional parameters may not be the same
if the covariance structure differs across groups.
Conversely, the same multidimensional parameters may correspond
to different parameter models.
The subsequent invariance of either the M2PL parameters
or the multidimensional ones may lead to different interpretations of
the same model when applied to different groups.
Although this is an empirical question that requires further research,
it could have significant implications for future theoretical developments
in the understanding of MIRT theory.

###### Are there standard computer programs that you would recommend to do the estimation/modeling you are proposing?

Our manuscript does not propose an estimation or modeling method.
On the contrary, what we propose is a way to compute and represent the multidimensional item parameters without disregarding the covariance structure of the latent space.
Implementing the formulae we propose should be rather straightforward for most IRT researchers, simply using the standard output of most MIRT software.
We have now added a discussion about this at the end of our fourth paragraph in the "Discussion" section. This addition reads:

> [...] Computing the parameters in the orthonormalized
(or just orthogonalized) space,
by contrast, would require transforming the cosines to
the original, non-orthonormal basis afterwards.
Nevertheless, most available MIRT software solutions,
such as flexMIRT [@cai_flexmirt_2024], IRTPRO [@cai_irtpro_2017],
or R package {mirt} [@chalmers_mirt_2012],
initially estimate an uncorrelated solution (at least in the exploratory case)
and apply an oblique rotation afterwards.
Taking advantage of the invariance property,
we may compute the parameters in the orthogonal space
(in fact, this is exactly what {mirt} functions `MDISC()` and `MDIFF()` do).
Then, we may compute the direction cosines in the rotated solution by applying
Equation (24).
<!-- TODO: Check Eq. nº afterwards -->
What a test practitioner should be aware of, though,
is that applying Reckase & McKinley's [-@reckase_discriminating_1991] formula
after any non-orthonormal transformation will yield
a $`r MDISC_AG_PARAM`$ value specific to that basis,
unlike the invariant value of $`r MDISC_COV_PARAM`$.

Notwithstanding, we have written extensive code in R for computing these parameters, which we intend to open up for public use and scrutiny in a GitHub repository that includes all the code, data, and examples (including all the R packages to re-create the necessary environment to grant computational reproducibility), allowing to generate all the tables, plots, and even the submitted versions of the manuscript.
Using dedicated functions in our code, any interested researcher will be able to compute the multidimensional parameters from the output of any MIRT software [e.g., {mirt}, @chalmers_mirt_2012; flexMIRT, @cai_flexmirt_2024].
As the journal guidelines [require a specific format for the Supplementary Material](https://www.cambridge.org/core/services/authors/publishing-supplementary-material),
we chose not to include the repository as additional material.
However, we have checked and the journal accepts and also encourages publishing additional materiales in [a proper, trusted repository](https://www.cambridge.org/core/services/where-to-share-your-data). 
We have thus made public our GitHub repository for the manuscript [Link URL obfuscated for blind peer-review] and indexed it in Software Heritage [Link URL obfuscated for blind peer-review] for identification with a SWHID.
For the sake of transparency, we have also made this addition to the manuscript, in section "Applications to Examples from the Literature", before the @reckase_multidimensional_2009 example:

> The interested reader can explore the complete code for these examples in the
indexed Software Heritage repository for this paper, specifically:
[URL obfuscated for blind peer-review]

# Responses to Reviewer 1:

###### 1. Introduction, too lengthy, 1-2 pages will be fine.

Our introduction is a bit less than four pages long.
We have provided concise paragraphs about the Multidimensional IRT model and its parameters, their assumptions, and our rationale for relaxing them.
Finally, a last paragraph presents the objectives of our research.
We honestly believe we have made a thorough effort to summarize the motivation of our research, and we find it difficult to shorten it further without losing relevant information to justify our work.
Therefore, we are sorry to say that we cannot comply with the reviewer's request to shorten the introduction.

###### 2. Introduction, do you have any hypothesis for the current study? Please briefly describe it at the end.

Our work is entirely theoretical and thus employs a purely deductive method.
Consequently, we do not have any hypothesis to test; rather, we present the results of our formal derivations, which address the objective described at the end of our introduction.

###### 3. The details about the datasets should be described here.

The datasets we use in our paper are examples of item parameter estimates, taken from the literature.
As they only serve exemplification purposes and are not the main focus of our article, we deem it more appropriate to describe their details in the corresponding section of the manuscript.
We have added a short reference to them in the last paragraph of our introduction (p. <!-- TODO: Complete -->, lines <!-- TODO: Complete -->), to make sure their pertinence as examples is clear.

> These examples, from the cognitive and the non-cognitive domain, respectively,
are taken from the MIRT literature:
One of them is a classic dataset, often used to exemplify
the use of the `r MODEL_ACRONYM` model [@reckase_multidimensional_2009];
the other one, an application in marketing research [@tezza_modelo_2018].

###### 4. Within or between multidimensional latent? This should be detailed.

We think the context makes it clear that we are referring to "within-item" multidimensionality.
In fact, the results are trivial in the "between-item" multidimensionality case,
as the `r MDISC_SYM` parameter reduces to the only non-null component of the $`r DISCR_VECTOR`$ parameter.
However, we acknowledge this terminology is prevalent in the current MIRT literature;
therefore, we have now explained this in our "Model formulation" section.
The end of the second paragraph reads now as follows:

> [...] Finally, it is worth noting that
this formulation assumes *within-item multidimensionality* in general,
which will be present whenever more than one component of $`r DISCR_VECTOR`$
is non-null.
However, the model can also account for *between-item multidimensionality*
if all items are unidimensional
(i.e., their $`r DISCR_VECTOR`$ parameters only have one non-null component).

###### 5. Limitation is missing and should be added here.

Our last two paragraphs mention the most important limitations of our work.
We clearly demarcate the limited scope of our conclusions, and warn against overgeneralizing our results to other MIRT models or the common factor model.
We have put a great effort into writing our limitations in a way that is elegant and, at the same time, avoids cliché sentences that add no value to our manuscript.
Therefore, we would rather not add a separate "Limitations" section.

###### 6. Conclusion is missing and should be added here.

Similarly to the previous comment, we believe that our conclusions are thoroughly and carefully elaborated in our "Discussion" section, and we would prefer not to add an explicit "Conclusions" header.

# Responses to Reviewer 2:

###### [...] it is difficult to ascertain its practical value, as it is unclear how it can be applied in the real world.

We understand that it may be difficult to see the practical value of our proposal.
However, we argue that our main contribution is solidly founded on sound formal derivations, and that its value lies in the theoretical contribution it represents.
In practical terms, we believe that our results may help better diagnose the validity of the items in multidimensional tests, as both the multidimensional parameters and the vector representation we put forward are a more faithful representation of the properties of those items.
This happens because item parameters should be interpreted in their context, that is, as properties of the response data that result from the interaction of an instrument and the sample where it is applied, as argued by @reckase_multidimensional_2009.

We expect that the changes we have made in the new version of our manuscript help clarify the practical value of our proposal.
In this respect, please see especially the responses to the editor in pp. <!-- TODO: Complete (3rd response, last, and 2nd to last) --> in this letter.

###### While the manuscript includes a graphical representation example with two-dimensional latent variables, real-world applications often involve higher dimensions (e.g., the Big Five personality traits or Cattell’s 16 personality factors). If the current results cannot be applied to the high-dimensional cases, would that significantly limit their practical value and applicability?

Although the graphical representation is limited to two dimensions, we propose a general algebraic formulation that accounts for any number of dimensions.
We have found that our previous version was not explicit enough about this, so we have updated the first paragraph of the "Model Formulation" section to read as follows:

> Consider a basis $`r LS_BASIS_EQ`$,
with $`r LS_BASIS`$ generally non-orthonormal.
Let $`r LATENT_SPACE`$ be a $`r N_DIMS`$-dimensional latent space
in basis $`r LS_BASIS`$ (with $`r N_DIMS`$ any positive integer),
where a respondent is represented by vector $`r TRAIT_VEC_IN_LS`$.
According to the `r MODEL_ACRONYM` model, the probability of
a positive response to item $`r ITEM_INDEX`$ is [...]

Also, the "Graphical Representation Example" section now begins:

> Up to now, all our derivations
have considered $`r N_DIMS`$-dimensional spaces;
that is, multidimensional parameters and item vector coordinates
can be computed in an arbitrary large number of dimensions.
However, as plotting more than two dimensions [...]

###### 1. In the 8th line from the bottom on page 9, the subscript in the formula is incorrect. It should be “$\mathcal{C}$”.

Thank you so much to Reviewer 2 for pointing out this typo.
We have corrected it in the manuscript accordingly.

###### 2. The notations in the manuscript lack clarity, particularly in Eq. (19) on page 12. Based on Eq. (5) and Eq. (15), $\mathbf{a}_i$ in the numerator of Eq. (19) should be $\mathbf{a}_i^{\mathcal{B}*}$.

This case was also a typo; we have now corrected it in the manuscript as well.

###### Similar issues occur in Eqs. (26) and (27) on page 17.

<!-- # TODO: Equation references change? -->
Our intention in Equations (26) and (27) was to express the item vector coordinates in terms of the original model parameters directly.
To do that, we have made use of the equality $`r DISCR_VECTOR_COORDS_EQ`$, stated on p. 7.
(That is, the geometric coordinates in the original test-space basis are equal to the algebraic values of the discrimination parameter.)
However, we acknowledge that we have skipped a step in our discourse, thus making it harder than necessary to follow along.
To correct this, we have modified the immediately preceding paragraph to the following:

<!-- # TODO: Confirm equation references -->
> Of course, from Equations (25) and (26), it is easy to express
the coordinates in terms of the parameters in the original model formulation.
Given $`r DISCR_VECTOR_COORDS_EQ`$,
we can express the coordinates in terms of the model parameters as

###### 3. In the second graph on page 18, the authors state, “*That is, the less discriminating the item, the further it will be from the origin.*” However, the value of $D_i$ is influenced not only by the $MDISC_i$ parameter but also by $d_i$. For instance, in Table 1 on page 20, $d_i$ for item 1 is zero, meaning that regardless of $MDISC_i$, $D_i$ remains zero.

The reviewer is right in this respect; we made the mistake of assuming this relationship was obvious enough, but we acknowledge it may confuse the reader to refer to the $MDISC_i$ and overlook the influence of $d_i$.
We have added a clarification to this at the end of the paragraph, which now reads:

> That is, the less discriminating the item is,
the further away it will be from the origin.
Of course, it is also directly proportional to
the intercept parameter $`r INTERCEPT_PARAM`$.
This implies that, if $`r INTERCEPT_NULL_EQ`$,
$`r DISTANCE_NULL_EQ`$ as well,
regardless of the multidimensional discrimination.

# Responses to Reviewer 3:

###### The manuscript highlights the fact that the coordinate system used to represent results typical of educational achievement and other types of social measures is at the discretion of the person performing the analysis, or the entities developing computer software, if default settings are used in the analysis.

Although we argue indeed that the coordinate system is arbitrary, our stance is also that there is a more interpretable approach than simply assuming orthogonal axes.
Such an approach implies that there is a geometric basis (and thus a coordinate system) that can be considered a faithful representation of the covariance structure.

###### This is a very important issue and it is not frequently discussed in the research literature. Two researchers can administer the identical instrument to samples of individuals with different characteristics – say typical high school students versus those who have a different native language – and get different representations of the test results from analyses programs, such as the correlations between estimated constructs.  This manuscript stimulates much thought related to this problem.

We are glad that the reviewer has found our work thought-provoking.
We argue indeed that different samples may yield different latent covariance structures.
While this problem has received much attention in the factor analysis literature (i.e., factorial invariance), it has been largely overlooked in the MIRT literature, where any covariance structure is usually represented in orthogonal axes (implying an orthonormal basis).

###### [...] I was at a loss at the end of the discussion to identify the interpretive or methodological value that was gained by working with non-orthogonal axes. The correlation between items can be represented by the angle between item vectors in the space with orthogonal axes, and the correlation between coordinates for persons can be represented by the shape of the scatter plot of points representing the individuals. How are these features interpreted when the coordinate axes are non-orthogonal?

We argue that non-orthogonal axes provide a faithful representation of the latent covariance structure.
We have made the following addition in the third paragraph of our introduction to reflect this fact:

> [...] the assimilation of correlated latent traits to non-orthogonal
axes is prevalent in the common factor literature
[see, e.g., @harman_modern_1976]:
Indeed, the cosine between any two axes (or, more generally, vectors)
is considered as the geometrical equivalent of the correlation between
the variables they represent. [...]

In geometrical terms, the cosine between axes directly maps to the correlation between the two dimensions represented by those axes.
In the orthogonal space, the angles between items are "distorted" and do not faithfully represent the correlation among those items.
We have now added a paragraph to our introduction to try to explain this fact intuitively.
Please refer to our answer to the editor on pp. 3-4 <!-- TODO: Review --> of this letter for more details on this addition.

Regarding the person parameters, the interpretation is more complicated:
If the original, correlated coordinates of the persons are represented in the orthogonal space, the shape of the scatter plot indeed represents the correlation between the latent trait coordinates.
However, our rationale is that a basis may be used such that, when the coordinates are transformed to an orthonormal one, the resulting scatter plot is spherical (i.e., its covariance is an identity matrix).
This results in a basis (and an associated coordinate system) that does not have a direct interpretation, save for being "the inverse transpose" of the basis where we argue the items are faithfully represented.
However, please bear in mind that this transformation in the latent space is a reasoning artifact to obtain the proper expression of the item parameters in the general case; for further explanation about this, please see our response to the editor in pp.  <!-- TODO: Complete (5th response) --> lines  <!-- TODO: Complete --> of this letter.
We have tried to convey this when explaining the rationale behind the covariance-based version of the parameters (see p. 14, lines 15-22, or p. <!-- TODO: Complete -->, lines <!-- TODO: Complete --> in the new version).

###### Care needs to be taken when using nonorthogonal coordinates that the distances between points in the space are correctly represented. What formula should be used for the distance between two points in each case?

The distances between points are given by the norm,
be it in the latent space or the test space.
We propose that the norm of both items and trait vectors should be invariant to
changes of basis and, interestingly, when considering the covariance-based version of the multidimensional parameters, the distance between points in the latent space is given by the Mahalanobis distance.
We have reflected this in our new version by adding the following to the end of the "Covariance-based Version" section:

> [...] Moreover, it is important to notice that,
when the latent trait inner product Gram matrix
is defined as $`r INNER_PROD_COV_COND`$,
the norm of a trait vector in the latent space is given by
the Mahalanobis distance, i.e., $`r MAH_DIST_EQ`$ [@mahalanobis_reprint_2018].

Also, we have made changes and additions to
the third  <!-- TODO: Review --> paragraph of our Discussion, which now reads:

> [...] Once again, this is relevant in applications where potentially different bases are involved.
Furthermore, we have found that using this version yields a norm in
the latent space given by the Mahalanobis distance.
This statistical distance not only takes
the latent covariance structure into account,
but also makes the latent space norm invariant to changes of basis. [...]

###### Page 3  Line 20 I could not find a discussion of nonorthogonal dimensions in Ackerman (2005). It would help if a page number were provided for the discussion.

We apologize for the lack of clarity.
We intended to refer to footnote 1 on page 16; we have now completed the reference.

###### I also wonder about the Harman (1970) reference. I know that he shows a plot of length of arm against length of leg using orthogonal axes for the plot even though the two measures are correlated. I am not not sure how the axes should be oriented to reflect the correlation between the two measures.

We intended to refer to section 4.8 (*Distance and Angle in General Cartesian Coordinates*), where he explains how to compute coordinates that "involve the inclination of the reference axes" [@harman_modern_1976, p. 60].
Please note that, as we do not have access to the 2nd edition anymore, we have used the 3rd one in our new version, and updated all the references accordingly.

Regarding the scatter plot you mention, we have not been able to find it (at least not in the 3^rd^ one we are using now, even though the example you refer to appears at the end of section 2.5, pp. 22-23).
However, we acknowledge that such a plot is the most common representation of the values realized by different cases (persons, in our case) in two variables, correlated or not.
In this regard, we would kindly refer you to our third <!-- TODO: Expressed ok? --> response to your comments, on p. <!-- TODO: Complete --> of this letter, where we discuss the representation of person parameters in the last two paragraphs.
<!-- TODO: Possibly complete with references to other responses? -->

###### Page 6  Line 21 The expression on this line needs more explanation. I am not sure what the expression is supposed to represent.

This is the expression of a vector represented in a basis, in this case, stating that the vector can be represented in each of the two bases interchangeably.
Following the reviewer's suggestion, we have added this clarification to the text, so it now reads:

> [...] such that $`r TRAIT_VECTOR_DEF_EQ`$.
That is, the geometric representation of the algebraic vector $`r TRAIT_VECTOR`$
in each of the two bases is given by the linear combination of
the element vectors of the basis,
scaled by the coordinates of $`r TRAIT_VECTOR`$ in that basis.
However, note that, as $`r LATENT_SPACE`$ is originally represented in
$`r LS_BASIS`$, the geometric coordinates $`r TRAIT_COORDS`$ of
$`r TRAIT_VECTOR`$ in $`r LS_BASIS`$ are equal to the algebraic ones,
i.e., $`r TRAIT_GEOM_ALGEBR_EQ`$.

###### Page 7  Line 24 The meaning of the superscripts is not clear in this expression. What is the source of the -1T?  Is that the transpose of the inverse? Do the -1 superscripts indicate an inverse?

The -1 superscripts indeed indicate the inverse of a matrix.
This has been an unfortunate typesetting problem of the submission system,
that renders the -1 and the *T* at the same height.
We have sorted this out by using parentheses, as you will be able to see in our new submission.

###### Page 13 Line 4 The implications of the word “indistinctly” in this sentence are not clear.

This is a mistake on our side, we are afraid to admit, the product of a careless translation of a false friend from our mother tongue Spanish ("indistintamente"), which means "indifferently".
We have changed the term to the mathematically appropriate "interchangeably" in our new version.

###### Page 13 Line 8 The statement “the test space is where the item parameters naturally lie” seems to imply there is a correct representation of the item parameters. But, the correlations between constructs changes with the sample of examinees and the coordinates can easily be rotated and translated giving different representations of the item parameters. I would like to see support for the statement.

We think that our word choice has been unfortunate here.
What we want to imply is that there are two different spaces, the latent space, and the test space, and that, unlike the latent traits, which "naturally lie" in the latent space, the item parameters "naturally lie in the test space", even though they can be projected onto the latent space.
This is implicit in the definition of the test space itself (see p. 7 line 8 in our original submission, or p. <!-- TODO: Complete --> line <!-- TODO: Complete --> in the new version), and is independent of the basis chosen to represent the items.
This basis does not necessarily need to be a geometric representation of the covariance structure, as we argue in our introduction, so it can be the canonical basis, or any other, orthonormal or not, and not necessarily representing the covariance structure.

We also argue that the test space and the latent space are two distinct spaces, even when the basis of the latent space (and, consequently, that of the test space) is orthonormal.
It is our understanding that,  due to a lack of need for this distinction, this is overlooked in Reckase's [-@reckase_difficulty_1985] and Reckase & McKinley's [-@reckase_discriminating_1991] original formulations.
We have added this latter clarification in our new version (p. <!-- TODO: Complete --> lines <!-- TODO: Complete -->):

> [...] the latent space,
where the person parameters are represented,
has the inverse of the covariance (correlation) matrix as
its inner product matrix.
[Note that in the original derivations by @reckase_difficulty_1985;
and @reckase_discriminating_1991, both matrices simplify to the identity matrix,
so there was no need to make this distinction.]
This implies that the axes defined by the test space basis, [...]

###### Page 19 Line 8 There is an interesting distinction that seems to be lost here. Attributes can be measured independently, such as height and weight and yield correlated results. Under those circumstances, should axes be represented as orthogonal, or should the axes represent the correlation. This has an implication for the formula that is used to compute the distance between points in the space.

As we mention above, when the attributes are correlated, a distance measure that keeps the norm invariant in the latent space is the Mahalanobis distance (please see our response on p. <!-- TODO: Complete --> in this letter).
In this respect, we should make the distinction between representing the attributes being measured (i.e., the latent traits) and the variables measuring those attributes (in our case, the items).
Our argument is that it is when we represent the items that we should use axes that "faithfully represent the covariance structure", regardless of how we represent the attributes.

###### Page 22 Figure 1 It seems that both of these plots are shown with orthogonal coordinate axes. But the orthogonal axes have changed so that the nonorthogonal axes can be shown in the orthogonal representation.

That is exactly the case.
All graphical devices require that coordinates are represented in a rectangular Cartesian system such that the first coordinate maps to the horizontal dimension and the second coordinate to the vertical one.
Therefore, even when computing the coordinates in a non-orthonormal basis, we need to transform them to the canonical one to plot them.
This is explained in our manuscript, on p. 19 (lines 9-14) in the original version, and on p. <!-- # TODO: Complete --> (lines <!-- # TODO: Complete -->) in the new submission.
We are unsure about how to make this clearer, we are afraid, so we would appreciate any suggestions.

###### Page 26 Line 8 This discussion seems to miss the distinction between correlations between traits and dimensions of sensitivity of the test items.

To our understanding, one may assume a theoretical dimensional sensitivity of a test space that is higher than the dimensionality of the latent space, which we acknowledge we may have overlooked.
However, in such a case, the (minimum) dimensionality of the data would be "the smaller of the dimensions or variation for the people and the dimensions of sensitivity for the test items" [@reckase_multidimensional_2009, p. 182].
That is, the dimensional sensitivity of the data would nevertheless be restricted by the dimensionality of the latent space.
This implies that the parameter values one can estimate for the items will represent a lower-dimensional solution, which would be the projection of the theoretically higher-dimensionally sensitive parameters on the lower-dimensional latent trait space, as discussed on p. 182 of @reckase_multidimensional_2009.
In practice, this implies that this solution is indistinguishable from one where the items are simply sensitive to the lower number of dimensions, with their parameters given by such a lower-dimensional solution, which would correspond to their projections from the alleged higher-dimensional space onto the lower-dimensional one.

As Reviewer 3 points out, the high correlations between traits and the restricted dimensionality they imply are different from the dimensional sensitivity of the test items.
However, a highly correlated latent space, as in dataset 3d1 in @reckase_multidimensional_2009, may induce a dimensional restriction on the latent space (as indicated by the rank-1 covariance matrix), which is indistinguishable from a lower-dimensional (unidimensional, in this case) solution.
These two facts, the indistinguishability of the "projected high-dimensional" solution and the lower-dimensional one, on the one hand, and the indistinguishability of the "high-dimensional solution" with a low-rank covariance matrix and the "low-dimensional solution", on the other, render the theoretical implications of a higher-dimensional item sensitivity impossible to test in a case like this example.
This is acknowledged by @reckase_multidimensional_2009, who states that "if the process used to generate the data were not known, the interpretation of the analysis results would likely be that the test items all measured the same construct and that the data could be well fit by a unidimensional IRT model" (p. 189).

However, in our manuscript, we intend to go one step further and show how the latent space covariance affects how the item parameters are interpreted.
We have shown that non-orthonormal axes are a more faithful geometrical representation of the test space when the latent covariance is not an identity matrix.
From the model formulation, one can note that the components of the discrimination parameter serve as a scaling factor of the effect each latent trait has on the response probability function.
As such, if they were interpreted as abstract parameters in a high-dimensional space that can be projected onto the latent trait axis, then the model formulation would consider those projections instead of the original item parameters.
Therefore, the discrimination parameter values should be considered as being "parallel" to the latent space axis.
In other words, each discrimination parameter value is itself the projection of the item vector length onto its corresponding axis.

In this sense, having such high correlations among latent traits not only makes them practically unidimensional; it also implies that the item parameters must be practically aligned with the "unidimensional" latent space axis.
In other words, even if a test is designed to be sensitive to three dimensions, if those three dimensions are highly correlated, the items will be practically sensitive to a single dimension.
This will happen regardless of whether one considers that there is a higher-dimensional test space from which the alleged single dimension is a subspace (where the item parameters will be a projection of the higher-dimensionally sensitive ones), or whether one considers that the items are simply sensitive to a single dimension, with the item parameters given simply by the 2PL model.
We believe this is the reason why estimating such a model would yield "a first dimension with high positive $`r DISCR_SYM`$-parameters and other dimensions with much lower $`r DISCR_SYM`$-parameter estimates with many around zero" [@reckase_multidimensional_2009, p. 189].
In fact, we predict that the non-zero discrimination value estimate will not match any of the values of the generating discrimination parameter, but $`r MDISC_COV_PARAM`$ which, in this case, actually matches the discrimination parameter of the unidimensional 2PL model.
Although we acknowledge the lack of time to properly check that this prediction is fulfilled, we will gladly do so in another review round if the editor and Reviewer 3 consider it necessary.

The aforementioned considerations have led us to use this edge case as a very illustrative example for our purposes, because it allows the reader to understand easily that all items should be aligned with the only dimension being measured.
It is therefore easy to grasp the intuitive notion that all direction cosines should be expected to be equal to 0, and in the more general case, to represent the relative alignment of the item vector with all the axes.
However, in doing so, we may have skipped a step in our reasoning, assimilating the dimensionality of the latent space with the dimensional sensitivity of the items, as Reviewer 3 points out.

To clarify this point better, we have tried to better express this distinction, emphasizing that, in this case, the unidimensionality induced by the rank-limited covariance matrix restricts the dimensional sensitivity of the test space.
The aforementioned paragraph now reads (p. <!-- # TODO: Complete -->, lines <!-- # TODO: Complete -->):

> [...] In that example,
he uses a covariance matrix that practically has rank 1,
implying that the (alleged) three latent dimensions collapse into a single one.
This makes the latent space unidimensional in practice,
which in turn restricts the dimensionality of any response dataset
generated from a test measuring those traits.
Therefore, "the data could be well fit by a unidimensional IRT model"
[@reckase_multidimensional_2009, p. 189].
In such a case, when all the items are strictly aligned with
the one dimension being measured,
we should expect the direction angles to be extremely close to 0 for all items.
The reader interested can check that this is the case for
the covariance-based version of the direction angles
in the table in Online Resource 1.

###### Page 29 Line 7 I am curious if the values of discrimination are comparable from the two representations. It seems that the metric of the representational space has changed, and equivalent numbers will not have equivalent meaning.

We are not completely sure to have understood this comment.
The discrimination values in the original `r MODEL_ACRONYM` metric are comparable, in the sense that they yield the same model probabilities for the same latent trait coordinates, independently of the covariance structure of the latent space.
However, the covariance-version of the multidimensional discrimination is different, and will indeed be dependent on the metric of the test space, which is defined by its geometrical basis, which determines the directions and scales of the axes.
In this case, the basis has been chosen to be a geometric representation of the correlation matrix (as given by the expression $`r INNER_PROD_CORR_COND`$, please see p. <!-- # TODO: Complete -->, line <!-- # TODO: Complete -->, in the new version), and therefore, the scales are not affected (only the relative directions among the axes).

We would kindly ask to elaborate further on this question if the Reviewer feels it has not been completely addressed.

###### Page 30 Line 8 It would be helpful to show the orthogonal and nonorthogonal representations of items and then discuss the interpretation of the parameter estimates based on each of the representations. I have been unable to determine the value of using the nonorthogonal representation. The nonorthogonal representation is more complex, and it seems sample dependent because it uses the observed correlations/covariances. What is the value added of using the more complex representation?

We have found this comment puzzling as, to our understanding, what Reviewer 3 is asking is what we do in Figure 1 (p. 22 in our original submission, p. <!-- # TODO: Complete --> in the new one).
We have shown the same items, with as many different cases as possible, represented in both orthogonal and nonorthogonal coordinates, and explained the interpretation of the multidimensional parameters in both spaces.
We would appreciate it if Reviewer 3 would kindly clarify this comment, so we can address it properly.

On the other hand, to our understanding, the representation is always sample dependent because the item parameters also are.
Our argument is that the non-orthogonal coordinate system is a more faithful representation of the latent covariance structure, as the cosines between the axes are the geometric equivalent of the latent trait correlations.
We argue that this is the value of using this more complex representation, and so we have tried to convey in our Discussion section (please see p. 31, line 19 to p. 32, line 4, in the original version).

We acknowledge, though, that this may have been explained without enough clarity, and therefore striven to improve this discussion.
The aforementioned paragraph now reads:

> [...] This implies that the axes defined by the test space basis,
and not the ones defined by the latent space basis,
are a geometrical representation of the covariance structure.
Indeed, the cosines of the angles among the test space axes are
the geometric equivalent of the correlations. [...]

# References
