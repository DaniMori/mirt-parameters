---
title:     |
  Parámetros multidimensionales en Teoría de Respuesta al Ítem:
  ¡Algo estamos haciendo mal!
author:    |
  <table>
    <tr>
      <td>Daniel Morillo, Ph.D.</td>
    </tr>
    <tr>
      <td>
        <center>
          [![](../www/slideshow-assets/github-logo.png){height="50"}](https://github.com/DaniMori/)&emsp;
          [![](../www/slideshow-assets/orcid.png){height="50"}](https://orcid.org/0000-0003-3021-3878)
        </center>
      </td>
    </tr>
  </table>
institute: |
  <table>
    <tr>
      <td>
        <center>
          [![](../www/slideshow-assets/logos_fac_psicologia.svg){height="120"}](https://www.uned.es/universidad/facultades/psicologia.html)
        </center>
      </td>
    </tr>
  </table>
bibliography:  ../www/Multidimensional-parameters-MCLM.bib
csl:           ../www/apa-old-doi-prefix.csl
date:          "2024-10-21"
date-meta:     "2024-11-27"
date-format:   long
editor:
  mode:        source
  markdown: 
    wrap:      sentence
    canonical: true
lang:          es
knitr:
  opts_knit: 
    root_dir:  here::here()
  opts_chunk: 
    results:   asis
format:
  revealjs:
    auto-stretch:            true
    code-annotations:        hover
    df-print:                paged
    fig-cap-location:        bottom
    incremental:             false
    keep-md:                 true
    link-external-newwindow: true
    self-contained:          true
    slide-number:            false
    theme:                   ../www/slideshow-assets/extra-styles.scss
    transition:              none
    view-distance:           3
    template-partials:
      - ../www/slideshow-assets/title-slide.html
---

# Introducción

```{r libraries}
library(tibble)
library(dplyr, warn.conflicts = FALSE)
library(knitr)
```

::: notes
-   Nombre de la presentación: Cero atractivo

-   Nuria me pide un título más llamativo

-   Lo mejor que puedo conseguir

-   ¿Por qué es relevante?

-   TRI muy usada en evaluación e investigación educativa

-   Poco en investigación psicológica (muestras "pequeñas" en comparación)

-   Pero hay un "paralelismo" entre ambas teorías (isomórficas, ante determinados supuestos)
:::

<!-- Slides "Diferencias AF - TRI" -->

```{r irt-fa-table}
af_tri_differences <- tribble(
  ~AF,                            ~TRI,
  "Relaciones entre variables",   "Comparación entre participantes",
  "Cuestionarios",                "Pruebas (rendimiento)",
  "Explicación",                  "Medición",
  "Puntuación compuesta",         "Puntuación latente",
  "Estructura simple",            "Diferencias individuales"
)

section_title <- "## Diferencias AF - TRI"

for (slide in af_tri_differences |> nrow() |> seq_len()) {
  
  cat( "\n", section_title, sep = '')
  
  af_tri_differences |> slice_head(n = slide) |> kable() |> print()
}
```

## AF: Estructura simple

<!--# TODO: Ejemplos estructura simple vs. compleja: Path diagram vs. coordenadas -->

::: notes
Para darle más sentido al modelo factorial es común buscar la "estructura simple".
Es decir, asumimos que la varianza de cada ítem está explicada solamente por un factor latente.
Los pesos factoriales en los demás factores son nulos.
Si representamos los pesos factoriales como coordenadas, el ítem estará alineado con el eje correspondiente al factor en el que pesa.
:::

## AF: Estructura simple

<!--# TODO: Ejemplo mostrando solución factorial sin rotar y ejes tras rotación oblicua? -->

::: notes
Para obtener esa estructura simple, muchas veces necesitamos usar una rotación oblicua.
:::

## AF: Estructura compleja

<!--# TODO: Ejemplo con pesos cruzados: Path diagram vs. coordenadas -->

::: notes
Sin embargo, en ocasiones no es posible encontrar la estructura simple.
Es cuando aparecen lo que llamamos "pesos cruzados".
Esto da lugar a una "estructura compleja", que en realidad es más común que la estructura simple, en general.
:::

## AF: Estructura compleja

<!--# TODO: Ejemplo con factores de método: Path diagram vs. coordenadas -->

::: notes
Por ejemplo, si tenemos ítems directos e inversos, podemos modelar lo que llamamos "factores de método": Una variable latente para cada factor sustantivo, y una para cada uno de los tipos de ítem.
:::

## Modelo factorial clásico

<!--# TODO: Fórmula del modelo factorial -->

<!--# TODO: Fórmula matricial para una variable observable -->

::: notes
Un modelo factorial no es más que una serie de regresiones lineales (una por cada variable observable) con variables latentes.
Las variables "respuesta" o "criterio" es la variable observable, y su varianza está explicada o "predicha" por las variables latentes, que son los factores y los términos de error de cada ítem.

Los "coeficientes de regresión" los llamamos "pesos factoriales" y el término error, "unicidad" o "varianza única".
Esto se puede expresar en "forma matricial" de esta manera.

<!--# TODO: Explicar cómo se calcula en forma matricial? -->

Tenemos costumbre de ver el análisis factorial en el contexto de variables cuantitativas (o que asumimos que lo son, por ejemplo en ítems Likert).
Sin embargo, se aplica también (e idealmente se debería aplicar) a variables discretas ordinales.
En este caso vamos a concretarlo en variables dicotómicas (p.ej. ante un ítem como "Soy muy responsable" las opciones de respuesta son sólo V/F).
Esto es una simplificación que rara vez se utiliza en cuestionarios no cognitivos, pero es interesante estudiarlo porque otros modelos pueden considerarse extensiones de este modelo.
:::

## Análisis factorial de ítems

<!--# TODO: Fórmula del modelo factorial con función de enlace probit -->

<!--# TODO: Función de enlace "normal acumulada" -->

<!--# TODO: Curva Gaussiana y curva normal acumulada -->

::: notes
El análisis factorial de ítems (dicotómicos) lo que hace es aplicar ese "modelo lineal general" a variables dicotómicas: Asume una "variable latente" lineal, con la misma fórmula anterior, y aplica una "función de umbral" en 0 (la respuesta es correcta o afirmativa, codificada como 1, si la variable latente es mayor que 0, o incorrecta o negativa, codificada como 0, si es menor).
Eso da una "probabilidad" de responder correcta o "afirmativamente" a un ítem.
:::

## AF: Puntuaciones factoriales

Métodos:

-   Regresión

-   Bartlett

-   **Máxima Verosimilitud**

-   **Estimación Modal Bayesiana Empírica**

<!--# TODO: Diagrama de CFA y de "CFA inverso" -->

::: notes
Los dos primeros métodos se aplican en AF lineal y están implementados en SPSS.
Consisten a grandes rasgos en calcular la puntuación factorial como una suma ponderada de las variables observables.
Es decir, algo así como "darle la vuelta a las flechas" de causalidad.
Lo que tiene más sentido, desde el punto de vista estadístico, es "estimar" qué puntuaciones factoriales hacen más probable para una participante dar las respuestas que ha dado.

Eso es lo que hacen los dos métodos de abajo (SPSS no los implementa creo), Máxima Verosimilitud, o esimación Modal Bayesiana.
Si habéis hecho esto con variables categóricas, entonces habéis aplicado la Teoría de Respuesta al Ítem, y a continuación veremos por qué.
:::

## Paralelismo AF - TRI

::::: columns
::: column
![](../www/slideshow-assets/cover_McDonald-1999.jpg){height="300px"}

[@mcdonald_test_1999]
:::

::: column
<!--# TODO: Citation by McDonald -->
:::
:::::

## Teoría de respuesta al ítem

<!--# TODO: Fórmula de modelo 2PL -->

<!--# TODO: Gráfica de discriminación alta/baja, dificultad alta/baja -->

<!--# TODO: Fórmula del parámetro de intersección y del modelo en forma pendiente-intersección -->

::: notes
La TRI, por su lado, asume que hay cada persona tiene una puntuación latente, y que su respuesta depende de esa puntuación, con un parámetro de discriminación que determina cómo de bien o mal mide el ítem, y uno de dificultad (aunque aquí prefiero llamarlo "de posición") que determina lo fácil o difícil que será dar una respuesta positiva (afirmativa, correcta, codificada como 1).
Esa posición representa el nivel de rasgo latente que da lugar a una probabilidad de .5 de dar la respuesta positiva.

Ahora bien, la posición se puede reformular como un parámetro de intersección.

Como se puede ver, esto también se trata de un "modelo lineal general".
En este caso, en lugar de una función probit (normal acumulada), la función de enlace es la función "logit".
Es decir, la respuesta a cada ítem se modela como una regresión logistica donde los predictores son las variables latentes.
:::

## Teoría de respuesta al ítem multidimensional

<!--# TODO: Fórmula de modelo M2PL -->

<!--# TODO: Gráfica tridimensional de modelo compensatorio (y "curvas de nivel"?) -->

::: notes
Una de las extensiones multidimensionales (más antiguas, y probablemente más obvias) de este modelo consiste simplemente en asumir que la respuesta se modela como una "regresión logística multivariada".

Esto da lugar a una familia de modelos llamados "compensatorios" en TRI, ya que un nivel bajo en una puntuación latente se compensa con un nivel alto en otra, dando lugar a la misma probabilidad de respuesta.
:::

## TRI multidimensional: Ejemplo

<!--# TODO: Valores, cálculo y gráfica -->

::: notes
Veamos un ejemplo de cuál sería la probabilidad de respuesta de una persona con puntuaciones de rasgo $\theta_1 = TODO$ y $\theta_2 = TODO$.

(Hacer cálculos matriciales)
:::

## AF en métrica TRI

<!--# TODO: Fórmulas de los modelos y de transformación de parámetros. -->

::: notes
A partir de las ecuaciones del AF y de TRI, es fácil ver que existe un paralelismo entre ambos modelos.
Es posible transformar los parámetros de la métrica del AF a métrica de TRI y, de hecho, esto es necesario, y se hace así para hacer la estimación máximo-verosimil de la que hablábamos antes.
:::

## TRI Multidimensional: Parámetros multidimensionales

<!--# TODO: Fórmula de modelo M2PL -->

@reckase_difficulty_1985:

> \[...\] means of describing the characteristics of an item that takes into account the dimensionality of the skills \[...\] can then be used to determine how or if it is possible to compare items that measure different combinations of abilities.

## Dificultad multidimensional

> \[...\] the most reasonable point to use in defining the MID for an item in the multidimensional space is the point where the item is most discriminating.

---(p. 402)

<!--# TODO: Fórmula del parámetro D_i -->

> The distance can be interpreted much like a $b$ parameter from unidimensional IRT

---(p. 405)

<!--# TODO: Representación de la curva de inflexión y la posición del ítem -->

::: notes
A pesar de este paralelismo, y de la utilidad de los modelos de TRI, hay un problema con la formulación del modelo que os he planteado, y es que como habéis podido ver los parámetros no son fácilmente interpretables.
La intersección del modelo no tiene una interpretación clara, al contrario que el parámetro de posición en la TRI unidimensional, que permite comparar ítems entre sí en cuanto a su dificultad.

Esto en AF no es muy habitual (prestamos poca atención a la "intersección" o "umbral"), porque no nos interesa tanto cómo de probable sea dar una respuesta positiva o negativa a un ítem, pero podría ayudarnos por ejemplo a diagnosticar ítems que estén mal diseñados, ya que nos da una idea de si va a haber muchas o pocas respuestas positivas a un ítem.

Por ese motivo Reckase propone en 1985 obtener un parámetro de "dificultad" (lo llama, para nosotro sería de posición) que permita comparar ítems, y que sea de algún modo equivalente a la dificultad en el modelo unidimensional.
Ese punto es donde la curva (superficie) de probabilidad de respuesta tiene una inflexión (a lo largo de toda ella, el punto más cercano al origen, donde la recta que lo une al origen es perpendicular a la recta de inflexión de la curva).

Este parámetro se puede entender como una "distancia con signo" desde el origen hasta el punto de posición del ítem.
:::

## Dificultad multidimensional

<!--# TODO: Fórmula de los cosenos directores -->

<!--# TODO: Representación gráfica de los cosenos directores? -->

<!--# TODO: Conjunto del MID -->

::: notes
Para representar ese punto no basta con la "distancia (con signo)"; hace falta saber en qué dirección mide ese ítem también.
Eso viene dado por los llamados "cosenos directores".

Por lo tanto, la "dificultad (posición) multidimensional" viene dada por dos elementos, un vector de cosenos que determina la dirección en la que mide un ítem, y un número entero que representa cuánto se desplaza respecto del origen, y en qué sentido, la recta de inflexión del ítem.
Así se puede interpretar un ítem, o varios, de manera relativamente sencilla: Todos los participantes cuyas coordenadas estén en la "recta de inflexión" (la recta que pasa por la posición del ítem, perpendicular a su dirección) tendrán una probabilidad de dar una respuesta positiva y negativa de .5 (dificultad media; igual probabilidad de acertar o fallar).
Aquellos que estén pasada la recta, encontrarán el ítem "relativamente fácil" (tendrán una alta probabilidad de dar una respuesta positiva mayor a .5; lo encontrarán "más fácil que difícil").
Lo contrario pasa para los que estén al otro lado de esa recta, tendrán más probabilidad de responder negativamente (mal), por lo que lo encontrarán difícil.

De lo que este parámetro no informa es de "cómo de fácil o difícil" va a ser el ítem para aquellos participantes que están muy cerca o muy lejos de esta recta.
Es decir, una vez estoy pasada la recta, aunque esté cerca, ¿es el ítem muy fácil, o más bien tengo que estar "muy lejos" (tener alta puntuación en uno u otro rasgo) para que sea más probable que de una respuesta positiva?
:::

## Discriminación multidimensional

@reckase_discriminating_1991:

> the discriminating power of an item indicates how quickly the transition takes place from low probability to high probability of a correct response.
> \[...\] A highly discriminating item divides the regions clearly-having a narrow region of ambiguity, that is, a region where the probabilities are intermediate in magnitude.

<!-- # TODO: Superficies de ítems con alta y baja discriminación -->

::: notes
Esta característica viene representada por el parámetro de "discriminación", que es una medida de la "calidad general" de un ítem.
Los ítems "buenos" serán muy discriminativos, lo que indica que distinguen bien entre la gente que tiene nivel de rasgo alto o bajo, mientras que los "malos" tendrán una superficie de respuesta más "plana".

La discriminación se puede entender con una especie de "dardo" que atraviesa de arriba abajo esa superficie perpendicularmente por esa "recta de inflexión" de la que hablábamos antes, y luego cruza el plano origen.
Si la superficie es "totalmente plana" el dardo entra por un punto y sale por otro que está justo debajo, en las mismas coordenadas de rasgo latente.
La "proyección" (si ponemos un foco justo encima, la sombra que forma en el plano) es un punto.
Es decir, la "discriminación" es cero (el vector del ítem tiene longitud "cero").
Si la pendiente es muy pronunciada (distingue bien entre niveles de rasgo) el dardo atravesará el plano origen muy lejos.
La sombra será muy larga (es decir, la discriminación muy alta).
El caso "extremo" es una superficie "vertical" en la recta de inflexión (un escalón; cosa imposible en ítems reales).
En este caso, el dardo nunca cortaría al plano origen, y la discriminación sería infinita.
:::

## Parámetros multidimensionales

@reckase_discriminating_1991:

<!-- # TODO: Fórmula de MDISC -->

<!-- # TODO: Gráfico del cálculo de MDISC como teorema de Pitágoras -->

<!-- # TODO: Fórmula de dificultad con MDISC -->

::: notes
@reckase_discriminating_1991 hacen la deducción de la discriminación multidimensional, y resulta dar lugar a esta fórmula.
Como veis es simplemente la "longitud" del vector de parámetros de discriminación, resultante simplemente de aplicar el teorema de Pitágoras.
El vector es un triángulo rectángulo, $a_1$ sería un cateto, el otro cateto sería igual a $a_2$, y la hipotenusa es la longitud (las dos discriminaciones al cuadrado, sumadas, y luego la raíz cuadrada de eso).
Esto por cierto también vale para cualquier número de dimensiones.
Aquí estamos representando sólo 2 porque es más fácil, pero podemos calcular la suma de cuadrados estos parámetros de discriminación (sea cual sea su número), y calcular su raíz cuadrada, y eso nos daría igualmente la discriminación multidimensional (la longitud de ese vector de $a$ del ítem).
:::

## Representación gráfica

@ackerman_graphical_1996:

::: notes
La propuesta de representación gráfica completa (y consistente) no llega hasta 1996.
Ackerman propone que el ítem se represente como un vector de longitud dada por la discriminación multidimensional, aplicado en la posición del ítem (y en la dirección dada por esa posición; es decir, todos los ítems "apuntan" siempre en la dirección que pasa por el origen).
:::


---@reckase_discriminating_1991

::: notes
A pesar de este paralelismo, y de estar clara la utilidad de los modelos de TRI, hay un problema con la formulación del modelo que os he planteado, y es que como habéis podido ver los parámetros no son fácilmente interpretables.
:::

## References {.smaller}
