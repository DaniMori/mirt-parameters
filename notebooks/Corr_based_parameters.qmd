---
title: "Parámetros basados en la matriz de correlaciones"
format: docx
callout-icon: false
editor: source
---

# Introducción

Tal y como Mario ha demostrado anteriormente, la versión "basada en la
correlación" de los parámetros multidimensionales no sería correcta, pues no
cumple la premisa de que "la matriz de covarianzas resultante" es diagonal.

No obstante, viendo las derivaciones matemáticas que ha hecho Mario también
respecto a cómo supuestamente obtener la base "verdadera" del espacio test
(en base a la descomposición espectral), creo que se puede encontrar una base
en el espacio test que cumpla esa relación.

# Deducción

## Supuestos iniciales

Como hemos hecho hasta ahora, asumimos un espacio $\mathbf{\Theta}$ con base
$\mathcal{B}$ y matriz Gramiana del producto interno $\mathbf{M}$ en el que se
representa el vector de rasgo latente $\mathbf{\theta}$. Este vector es una
variable aleatoria $n$-variada que se distribuye con covarianza
$\mathbf{\Sigma} = \mathbf{S} \mathbf{R} \mathbf{S}$, siendo $\mathbf{R}$ una
matriz de correlaciones, semidefinida positiva y con 1's en la diagonal, y
$\mathbf{S}$ una matriz diagonal de desviaciones típicas, tal que
$\sigma^2_{ii} = s^2_{ii}$, para todo $i$ entre 1 y $n$ (i.e., los elementos
diagonales de $\mathbf{\Sigma}$ y $\mathbf{S}^2$ son iguales).

Sea $\mathbf{P}$ la matriz de transformación de la base $\mathcal{B}$ a la base
$\mathcal{U}$. Las coordenadas de $\mathbf{\theta}$, expresadas en la base
$\mathcal{U}$, vienen dadas por la siguiente relación:

$$
\mathbf{\theta}^\mathcal{U} = \mathbf{P} \mathbf{\theta}
$$

Como ya sabemos,
$\mathbf{P} = [\mathbf{b}_1^\mathcal{U}, ..., \mathbf{b}_n^\mathcal{U}]$, es
decir, los vectores de la base $\mathcal{B}$ representados en la base
$\mathcal{U}$. Asumamos además que $\mathcal{U}$ es una base ortonormal,
con producto interno estándar. Sabemos entonces que
$\mathbf{P}^T \mathbf{P} = \mathbf{M}$.

## Premisa

Es posible encontrar en el espacio latente $\mathbf{\Theta}$ una matriz de
transformación $\mathbf{P}$ de $\mathcal{B}$ en $\mathcal{U}$ tal que
$\mathbf{\Sigma}^\mathcal{U}$ sea una matriz diagonal, siendo
$\mathbf{M} = \mathbf{R}^{-1}$.

## Demostración

La matriz de covarianzas $\mathbf{\Sigma}^\mathcal{U}$ de
$\mathbf{\theta}^\mathcal{U}$ cumple

$$
(\mathbf{S}^\mathcal{U})^2 = \mathbf{P} \mathbf{\Sigma} \mathbf{P}^T,
$$

siendo $\mathbf{S}^\mathcal{U}$ una matriz diagonal de desviaciones típicas de
$\mathbf{\theta}^\mathcal{U}$.

Puesto que $\mathbf{P}^T \mathbf{P} = \mathbf{R}^{-1}$,

$$
(\mathbf{S}^\mathcal{U})^2 =
  \mathbf{P} \mathbf{S} (\mathbf{P}^T \mathbf{P})^{-1} \mathbf{S} \mathbf{P}^T.
$$

Operando, tenemos que

$$
\mathbf{P}^{-1} (\mathbf{S}^\mathcal{U})^2 (\mathbf{P}^{-1})^T =
  \mathbf{S} (\mathbf{P}^{-1})^T
  \mathbf{P}^{-1} \mathbf{S},
$$

$$
\mathbf{P}^{-1} \mathbf{S}^\mathcal{U}
  (\mathbf{P}^{-1} \mathbf{S}^\mathcal{U})^T =
    (\mathbf{P}^{-1} \mathbf{S})^T
    \mathbf{P}^{-1} \mathbf{S},
$$

Por lo tanto, podemos igualar
$\mathbf{P}^{-1} \mathbf{S}^\mathcal{U} = (\mathbf{P}^{-1} \mathbf{S})^T$.

Operando,

$$
\mathbf{S}^\mathcal{U} = \mathbf{P} \mathbf{S} (\mathbf{P}^{-1})^T,
$$
